# -*- coding: utf-8 -*-
"""preprocess.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/10Jjz8zCIYFliOfRi0nLQQgOuuSsOB1y6
**Project 1 group 8**
# **Data Preprocessing Stage**
## **Read data from file**
"""

import os
import codecs
import pandas as pd

def readfile(filename):
    current_path=os.path.abspath(os.curdir)
    file_path=os.path.join(current_path,filename)
    if not os.path.exists(file_path):
        print("error:file not found:"+filename)
        return ""
    f=codecs.open(file_path,"r","utf-8")
    s=f.read()
    f.close()
    return s
test_data=readfile("test-public.txt")
test_data=test_data.splitlines()
print("length of testing data:"+str(len(test_data)))
train_data=readfile("train.txt")
train_data=train_data.splitlines()
print("length of training data:"+str(len(train_data)))

"""## **preprocessing data**
- training data
"""

train_list=[]
for line in train_data:
    # remove \n at the end of each line
    line = line.strip()
    # split IDs by \t
    line_list = line.split("\t")
    train_list.append(line_list)
# print(train_list[0])


"""- testing data
*remove first line (no data)*
"""
del test_data[0]

test_list=[]

for temp_str in test_data:
    temp=temp_str.split('\t')
    temp_list=[]
    temp_list.append((temp[0]))
    temp_list.append((temp[1]))
    temp_list.append((temp[2]))
    test_list.append(temp_list)
print("preprocessed testing data length:"+str(len(test_list)))

"""**check validity**"""

#print(test_list)
#
""" Similarity Model """

from collections import defaultdict

follow = defaultdict(set)
follower = defaultdict(set)



for instance in train_list:
    source,sink_list = instance[0],instance[1:]
#    if source == '3563811':
 #       print("abc")
    follow[source] = set(sink_list)
#    print(len(set(sink_list)))
    for node in sink_list:
#        node_set.add(node)
        follower[node].add(source)
#print(follow)
    # print(follow)
#print(follow['3563811'].union(follower['3563811']))



def Jaccard(node1,node2,Dict1,Dict2):
    user1 = Dict1[node1].union(Dict2[node1])
    user2 = Dict1[node2].union(Dict2[node2])

    if len(user1.union(user2)) == 0:
 #       print (node1,node2)
        return 0
    return float(len(user1.intersection(user2))/(len(user1.union(user2))))

Result = []
for ID, source, sink in test_list:
    Result.append([ID, Jaccard(source, sink, follow,follower)])



# output
title = ["Id", "Predicted"]
test_pd = pd.DataFrame(columns = title, data = Result)
test_pd.to_csv('/Users/elvis/Desktop/Result.csv', encoding='utf-8')
